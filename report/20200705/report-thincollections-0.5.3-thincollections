[[reports]]
level = 'Warning'
analyzer = 'UnsafeDestructor'
description = 'unsafe block detected in drop'
location = 'src/thin_map.rs:1606:1: 1637:2'
source = '''
impl<K: ThinSentinel + Eq + Hash, V, H: BuildHasher> Drop for ThinMap<K, V, H> {
    fn drop(&mut self) {
        if self.table_size > 0 {
            unsafe {
                if mem::needs_drop::<(K, V)>() {
                    if self.occupied_sentinels > 0 {
                        let mut ptr: *mut (K, V) = self.table.offset(-2);
                        if (*ptr).0 == K::thin_sentinel_zero() {
                            ptr::drop_in_place(ptr);
                        }
                        ptr = ptr.add(1);
                        if (*ptr).0 == K::thin_sentinel_one() {
                            ptr::drop_in_place(ptr);
                        }
                    }
                    if self.occupied > 0 {
                        let mut ptr: *mut (K, V) = self.table;
                        let table_end = self.table.add(self.table_size);
                        while ptr < table_end {
                            if K::thin_sentinel_zero() != (*ptr).0 && K::thin_sentinel_one() != (*ptr).0 {
                                ptr::drop_in_place(ptr);
                            }
                            ptr = ptr.add(1);
                        }
                    }
                }
                let layout = Layout::from_size_align(mem::size_of::<(K, V)>() * (self.table_size + 2), mem::align_of::<(K, V)>()).unwrap();
                alloc::dealloc(self.table.offset(-2) as *mut u8, layout);
            }
        }
    }
}'''

[[reports]]
level = 'Warning'
analyzer = 'UnsafeDestructor'
description = 'unsafe block detected in drop'
location = 'src/thin_map.rs:2000:1: 2023:2'
source = '''
impl<K: ThinSentinel + Eq, V> Drop for IntoIter<K, V> {
    fn drop(&mut self) {
        if !self.table.is_null() {
            unsafe {
                if mem::needs_drop::<(K, V)>() {
                    if !self.sentinel_zero_ptr.is_null() {
                        ptr::drop_in_place(self.sentinel_zero_ptr);
                    }
                    if !self.sentinel_one_ptr.is_null() {
                        ptr::drop_in_place(self.sentinel_one_ptr);
                    }
                    while self.cur < self.end {
                        if K::thin_sentinel_zero() != (*self.cur).0 && K::thin_sentinel_one() != (*self.cur).0 {
                            ptr::drop_in_place(self.cur);
                        }
                        self.cur = self.cur.add(1);
                    }
                }
                let layout = Layout::from_size_align(mem::size_of::<(K, V)>() * (self.table_size + 2), mem::align_of::<(K, V)>()).unwrap();
                alloc::dealloc(self.table.offset(-2) as *mut u8, layout);
            }
        }
    }
}'''

[[reports]]
level = 'Warning'
analyzer = 'UnsafeDestructor'
description = 'unsafe block detected in drop'
location = 'src/thin_v64.rs:1789:1: 1828:2'
source = '''
impl<T> Drop for V64<T> {
    fn drop(&mut self) {
        unsafe {
            if mem::size_of::<T>() == 0 {
                self.u = NonZeroU64::new_unchecked(ZST_MASK);
                return;
            }
            match self.control() {
                Control::Heap(ptr) => {
                    let len_ptr = ptr as *mut usize;
                    let header_bytes = cmp::max(mem::size_of::<usize>() * 2, mem::align_of::<T>());

                    if mem::needs_drop::<T>() {
                        let mut cur = (len_ptr as *mut u8).add(header_bytes) as *mut T;
                        let end = cur.add(*len_ptr);
                        while cur < end {
                            ptr::drop_in_place(cur);
                            cur = cur.add(1);
                        }
                    }

                    let align = cmp::max(16, mem::align_of::<T>());
                    let layout = Layout::from_size_align(mem::size_of::<T>() * (*(len_ptr.add(1))) + header_bytes, align).unwrap();
                    alloc::dealloc(ptr, layout);
                }
                Control::Stack(len) => {
                    if mem::needs_drop::<T>() {
                        let mut cur = self.stack_ptr();
                        let end = cur.add(len);
                        while cur < end {
                            ptr::drop_in_place(cur);
                            cur = cur.add(1);
                        }
                    }
                }
            }
            self.u = NonZeroU64::new_unchecked(8);
        }
    }
}'''

[[reports]]
level = 'Warning'
analyzer = 'UnsafeDestructor'
description = 'unsafe block detected in drop'
location = 'src/thin_v64.rs:2280:1: 2297:2'
source = '''
impl<T> Drop for IntoIter<T> {
    fn drop(&mut self) {
        if mem::size_of::<T>() == 0 { return; }
        // destroy the remaining elements
        for _x in self.by_ref() {}

        unsafe {
            if self.is_heap {
                let len_ptr = self.buf as *mut usize;
                let header_bytes = cmp::max(mem::size_of::<usize>() * 2, mem::align_of::<T>());
                let align = cmp::max(16, mem::align_of::<T>());
                let layout = Layout::from_size_align(mem::size_of::<T>() * (*(len_ptr.add(1))) + header_bytes, align).unwrap();
                alloc::dealloc(self.buf, layout);
                self.is_heap = false;
            }
        }
    }
}'''

[[reports]]
level = 'Warning'
analyzer = 'UnsafeDestructor'
description = 'unsafe block detected in drop'
location = 'src/thin_v64.rs:2409:1: 2429:2'
source = '''
impl<'a, T> Drop for Drain<'a, T> {
    fn drop(&mut self) {
        // exhaust self first
        self.for_each(drop);

        if self.tail_len > 0 {
            unsafe {
                let source_vec = self.vec.as_mut();
                // memmove back untouched tail, update to new length
                let start = source_vec.len();
                let tail = self.tail_start;
                if tail != start {
                    let src = source_vec.as_ptr().offset(tail as isize);
                    let dst = source_vec.as_mut_ptr().offset(start as isize);
                    ptr::copy(src, dst, self.tail_len);
                }
                source_vec.set_len(start + self.tail_len);
            }
        }
    }
}'''

[[reports]]
level = 'Warning'
analyzer = 'UnsafeDestructor'
description = 'unsafe block detected in drop'
location = 'src/thin_v64.rs:2470:1: 2508:2'
source = '''
impl<'a, I: Iterator> Drop for Splice<'a, I> {
    fn drop(&mut self) {
        self.drain.by_ref().for_each(drop);
//        unsafe { self.drain.vec.as_ref().debug_i32(); }

        unsafe {
            if self.drain.tail_len == 0 {
                self.drain.vec.as_mut().extend(self.replace_with.by_ref());
                return;
            }

            // First fill the range left by drain().
            if !self.drain.fill(&mut self.replace_with) {
                return;
            }

            // There may be more elements. Use the lower bound as an estimate.
            let (lower_bound, _upper_bound) = self.replace_with.size_hint();
            if lower_bound > 0 {
                self.drain.move_tail(lower_bound);
                if !self.drain.fill(&mut self.replace_with) {
                    return;
                }
            }

            // Collect any remaining elements.
            // This is a zero-length vector which does not allocate if `lower_bound` was exact.
            let mut collected = self.replace_with.by_ref().collect::<V64<I::Item>>().into_iter();
            // Now we have an exact count.
            if collected.len() > 0 {
                self.drain.move_tail(collected.len());
                let filled = self.drain.fill(&mut collected);
                debug_assert!(filled);
                debug_assert_eq!(collected.len(), 0);
            }
        }
        // Let `Drain::drop` move the tail back if necessary and restore `vec.len`.
    }
}'''

[[reports]]
level = 'Warning'
analyzer = 'UnsafeDestructor'
description = 'unsafe block detected in drop'
location = 'src/thin_v64.rs:2624:1: 2633:2'
source = '''
impl<'a, T, F> Drop for DrainFilter<'a, T, F>
    where F: FnMut(&mut T) -> bool,
{
    fn drop(&mut self) {
        self.for_each(drop);
        unsafe {
            self.vec.set_len(self.old_len - self.del);
        }
    }
}'''

[[reports]]
level = 'Warning'
analyzer = 'UnsafeDestructor'
description = 'unsafe block detected in drop'
location = 'src/thin_vec.rs:1568:1: 1594:2'
source = '''
impl<T> Drop for ThinVec<T> {
    fn drop(&mut self) {
        unsafe {
            if mem::size_of::<T>() == 0 {
                self.u = NonZeroUsize::new_unchecked(ZST_MASK);
                return;
            }
            if self.u.get() == DANGLE { return; }
            let len_ptr = self.u.get() as *mut usize;
            let header_bytes = <ThinVec<T>>::header_bytes();

            if mem::needs_drop::<T>() {
                let mut cur = (len_ptr as *mut u8).add(header_bytes) as *mut T;
                let end = cur.add(*len_ptr);
                while cur < end {
                    ptr::drop_in_place(cur);
                    cur = cur.add(1);
                }
            }

            let align = cmp::max(mem::align_of::<usize>(), mem::align_of::<T>());
            let layout = Layout::from_size_align(mem::size_of::<T>() * (*(len_ptr.add(1))) + header_bytes, align).unwrap();
            alloc::dealloc(self.u.get() as *mut u8, layout);
            self.u = NonZeroUsize::new_unchecked(DANGLE);
        }
    }
}'''

[[reports]]
level = 'Warning'
analyzer = 'UnsafeDestructor'
description = 'unsafe block detected in drop'
location = 'src/thin_vec.rs:2038:1: 2054:2'
source = '''
impl<T> Drop for IntoIter<T> {
    fn drop(&mut self) {
        if mem::size_of::<T>() == 0 { return; }
        // destroy the remaining elements
        for _x in self.by_ref() {}

        unsafe {
            if !self.buf.is_null() {
                let len_ptr = self.buf as *mut usize;
                let align = cmp::max(mem::align_of::<usize>(), mem::align_of::<T>());
                let layout = Layout::from_size_align(mem::size_of::<T>() * (*(len_ptr.add(1))) + <ThinVec<T>>::header_bytes(), align).unwrap();
                alloc::dealloc(self.buf, layout);
                self.buf = ptr::null_mut();
            }
        }
    }
}'''

[[reports]]
level = 'Warning'
analyzer = 'UnsafeDestructor'
description = 'unsafe block detected in drop'
location = 'src/thin_vec.rs:2166:1: 2186:2'
source = '''
impl<'a, T> Drop for Drain<'a, T> {
    fn drop(&mut self) {
        // exhaust self first
        self.for_each(drop);

        if self.tail_len > 0 {
            unsafe {
                let source_vec = self.vec.as_mut();
                // memmove back untouched tail, update to new length
                let start = source_vec.len();
                let tail = self.tail_start;
                if tail != start {
                    let src = source_vec.as_ptr().offset(tail as isize);
                    let dst = source_vec.as_mut_ptr().offset(start as isize);
                    ptr::copy(src, dst, self.tail_len);
                }
                source_vec.set_len(start + self.tail_len);
            }
        }
    }
}'''

[[reports]]
level = 'Warning'
analyzer = 'UnsafeDestructor'
description = 'unsafe block detected in drop'
location = 'src/thin_vec.rs:2227:1: 2265:2'
source = '''
impl<'a, I: Iterator> Drop for Splice<'a, I> {
    fn drop(&mut self) {
        self.drain.by_ref().for_each(drop);
//        unsafe { self.drain.vec.as_ref().debug_i32(); }

        unsafe {
            if self.drain.tail_len == 0 {
                self.drain.vec.as_mut().extend(self.replace_with.by_ref());
                return;
            }

            // First fill the range left by drain().
            if !self.drain.fill(&mut self.replace_with) {
                return;
            }

            // There may be more elements. Use the lower bound as an estimate.
            let (lower_bound, _upper_bound) = self.replace_with.size_hint();
            if lower_bound > 0 {
                self.drain.move_tail(lower_bound);
                if !self.drain.fill(&mut self.replace_with) {
                    return;
                }
            }

            // Collect any remaining elements.
            // This is a zero-length vector which does not allocate if `lower_bound` was exact.
            let mut collected = self.replace_with.by_ref().collect::<ThinVec<I::Item>>().into_iter();
            // Now we have an exact count.
            if collected.len() > 0 {
                self.drain.move_tail(collected.len());
                let filled = self.drain.fill(&mut collected);
                debug_assert!(filled);
                debug_assert_eq!(collected.len(), 0);
            }
        }
        // Let `Drain::drop` move the tail back if necessary and restore `vec.len`.
    }
}'''

[[reports]]
level = 'Warning'
analyzer = 'UnsafeDestructor'
description = 'unsafe block detected in drop'
location = 'src/thin_vec.rs:2381:1: 2390:2'
source = '''
impl<'a, T, F> Drop for DrainFilter<'a, T, F>
    where F: FnMut(&mut T) -> bool,
{
    fn drop(&mut self) {
        self.for_each(drop);
        unsafe {
            self.vec.set_len(self.old_len - self.del);
        }
    }
}'''

[[reports]]
level = 'Warning'
analyzer = 'UnsafeDestructor'
description = 'unsafe block detected in drop'
location = 'src/cla_map.rs:307:1: 342:2'
source = '''
impl<K: Eq + Hash + Debug, V: Debug, H: BuildHasher> Drop for ClaMap<K, V, H> {
    fn drop(&mut self) {
        if self.table_blocks > 0 {
            unsafe {
                if self.occupied > 0 {
                    let mut ptr: *mut u64 = self.table;
                    let table_end = self.table.add(self.table_blocks << 3);
                    while ptr < table_end {
                        let block_ptr = ptr as *mut u8;
                        let control_ptr = block_ptr.offset(63);
                        let count = (*control_ptr & 0x7F) as i8;
                        let mut kptr: *mut K = block_ptr as *mut K;
                        let mut i = 0;
                        while i < count {
                            ptr::drop_in_place(kptr);
                            i += 1;
                            kptr = kptr.add(1);
                        }
                        if mem::size_of::<V>() > 0 {
                            i = 0;
                            let mut vptr = block_ptr.offset(self.block_v_offset as isize) as *mut V;
                            while i < count {
                                ptr::drop_in_place(vptr);
                                i += 1;
                                vptr = vptr.add(1);
                            }
                        }
                        ptr = ptr.add(8);
                    }
                }
                let layout = Layout::from_size_align(self.table_blocks * 64, 64).unwrap();
                alloc::dealloc(self.table as *mut u8, layout);
            }
        }
    }
}'''

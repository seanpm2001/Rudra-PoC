[[reports]]
level = 'Warning'
analyzer = 'UnsafeDestructor'
description = 'unsafe block detected in drop'
location = 'src/wake_set.rs:155:1: 168:2'
source = '''
impl Drop for SharedWakeSet {
    fn drop(&mut self) {
        let wake_set = self.wake_set.load(Ordering::Acquire);
        debug_assert!(!wake_set.is_null());

        // Safety: At this point, there are no other ways to access the
        // `SharedWakeSet`, so we are not racing against someone trying to call
        // wake. Nor are we racing against `Unordered` dropping the wake set
        // since this is the active set which has been swapped in exclusively.
        unsafe {
            drop(Box::from_raw(wake_set));
        }
    }
}'''

[[reports]]
level = 'Warning'
analyzer = 'UnsafeDestructor'
description = 'unsafe block detected in drop'
location = 'src/lib.rs:676:1: 699:2'
source = '''
impl<T, S> Drop for Unordered<T, S>
where
    S: Sentinel,
{
    fn drop(&mut self) {
        // Cancel all child futures in an attempt to prevent them from
        // attempting to call wake on the shared wake set.
        self.slab.clear();

        // We intend to drop both wake sets. Therefore we need exclusive access
        // to both wakers. Unfortunately that means that at this point, any call
        // to wakes will have to serialize behind the shared wake set while the
        // alternate set is being dropped.
        let _write = self.shared.wake_set.prevent_drop_write();

        // Safety: we uniquely own `alternate`, so we are responsible for
        // dropping it. This is asserted when we swap it out during a poll by
        // calling WakeSet::lock_exclusive. We are also the _only_ one
        // swapping `wake_alternative`, so we know that can't happen here.
        unsafe {
            drop(Box::from_raw(self.alternate));
        }
    }
}'''

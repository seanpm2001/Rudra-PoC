[[reports]]
level = 'Warning'
analyzer = 'UnsafeDestructor'
description = 'unsafe block detected in drop'
location = 'src/tls/mod.rs:355:1: 371:2'
source = '''
impl<T> Drop for ThreadLocal<T> {
    fn drop(&mut self) {
        let mut tables = Vec::new();

        // Method free_nodes means we are only freeing node pointers but not
        // clearing them (no need to clear since nobody will ever use them
        // again, we are dropping the TLS).
        //
        // This is safe because we never load the nodes again.
        unsafe { self.top.free_nodes(&mut tables) }

        while let Some(mut table) = tables.pop() {
            // This is safe because we never load the nodes again.
            unsafe { table.free_nodes(&mut tables) }
        }
    }
}'''

[[reports]]
level = 'Warning'
analyzer = 'UnsafeDestructor'
description = 'unsafe block detected in drop'
location = 'src/queue.rs:154:1: 164:2'
source = '''
impl<T> Drop for Queue<T> {
    fn drop(&mut self) {
        let front = self.front.get_mut();
        while let Some(nnptr) = NonNull::new(*front) {
            // This is safe because we only store pointers allocated via
            // `OwnedAlloc`. Also, we have exclusive access to this pointer.
            let mut node = unsafe { OwnedAlloc::from_raw(nnptr) };
            *front = *node.next.get_mut();
        }
    }
}'''

[[reports]]
level = 'Warning'
analyzer = 'UnsafeDestructor'
description = 'unsafe block detected in drop'
location = 'src/map/bucket.rs:402:1: 439:2'
source = '''
impl<K, V> Drop for Bucket<K, V> {
    fn drop(&mut self) {
        unsafe {
            let ptr = self.list.atomic.load(Relaxed);
            let sentinel = NonNull::new_unchecked(ptr);
            let mut top = sentinel.as_ref().next;
            // Ok to deallocate it now since we already retrieved information.
            // Note that we have exclusive access to the bucket.
            OwnedAlloc::from_raw(sentinel);

            while let Some(list) = NonNull::new(top) {
                let ptr = list.as_ref().atomic.load(Relaxed);
                // By-passing this null check is ok because we never store null
                // pointer on the list's AomticPtr.
                let entry = NonNull::new_unchecked(ptr);
                // Ok to deallocate it now since we already retrieved
                // information. Note that we have exclusive
                // access to the bucket.
                OwnedAlloc::from_raw(list);

                let next = if entry.as_ref().next as usize & 1 == 0 {
                    // If the node is *not* marked, this entry was not removed
                    // and the pair needs to be deallocated. Ok to deallocate
                    // since we have exclusive reference.
                    OwnedAlloc::from_raw(entry.as_ref().pair);
                    entry.as_ref().next
                } else {
                    (entry.as_ref().next as usize & !1) as *mut _
                };
                // Ok to deallocate it now since we already retrieved
                // information. Note that we have exclusive
                // access to the bucket.
                OwnedAlloc::from_raw(entry);
                top = next;
            }
        }
    }
}'''

[[reports]]
level = 'Warning'
analyzer = 'UnsafeDestructor'
description = 'unsafe block detected in drop'
location = 'src/map/insertion.rs:155:1: 174:2'
source = '''
impl<F, K, V> Drop for InsertNew<F, K, V>
where
    F: FnMut(&K, Option<&mut V>, Option<&(K, V)>) -> Preview<V>,
{
    fn drop(&mut self) {
        // Must be safe. Callers should forget the inserter if they are
        // using the pointer. Note we check if the value is uninitialized.
        if self.is_val_init {
            unsafe { OwnedAlloc::from_raw(self.nnptr) };
        } else {
            unsafe {
                {
                    let (key, _) = self.nnptr.as_mut();
                    (key as *mut K).drop_in_place();
                }
                UninitAlloc::from_raw(self.nnptr);
            }
        }
    }
}'''

[[reports]]
level = 'Warning'
analyzer = 'UnsafeDestructor'
description = 'unsafe block detected in drop'
location = 'src/map/guard.rs:252:1: 258:2'
source = '''
impl<K, V> Drop for Removed<K, V> {
    fn drop(&mut self) {
        // We own the allocation. This must be safe.
        let alloc = unsafe { OwnedAlloc::from_raw(self.nnptr) };
        self.origin.upgrade().map(|incin| incin.add(Garbage::Pair(alloc)));
    }
}'''

[[reports]]
level = 'Warning'
analyzer = 'UnsafeDestructor'
description = 'unsafe block detected in drop'
location = 'src/map/mod.rs:403:1: 417:2'
source = '''
impl<K, V, H> Drop for Map<K, V, H> {
    fn drop(&mut self) {
        let mut tables = Vec::new();

        // Safe because we won't use these nodes anymore. We are in the
        // destructor.
        unsafe { self.top.free_nodes(&mut tables) }

        while let Some(mut table) = tables.pop() {
            // Safe because we won't use these nodes anymore. We are in the
            // destructor.
            unsafe { table.free_nodes(&mut tables) }
        }
    }
}'''

[[reports]]
level = 'Warning'
analyzer = 'UnsafeDestructor'
description = 'unsafe block detected in drop'
location = 'src/channel/spsc.rs:87:1: 110:2'
source = '''
impl<T> Drop for Sender<T> {
    fn drop(&mut self) {
        // This dereferral is safe because the queue will always have at least
        // one node. Also, we only put nodes allocated from `OwnedAlloc`.
        let res = unsafe {
            // Let's try to mark next's bit so that receiver will see we
            // disconnected, if it hasn't disconnected by itself. It is ok to
            // just swap, since we have only two possible values (null and
            // null | 1) and we everyone will be setting to the same value
            // (null | 1).
            self.back
                .as_ref()
                .next
                .swap((null_mut::<Node<T>>() as usize | 1) as *mut _, Relaxed)
        };

        // If the previously stored value was not null, receiver has already
        // disconnected. It is safe to drop because we are the only ones that
        // have a pointer to the node.
        if !res.is_null() {
            unsafe { OwnedAlloc::from_raw(self.back) };
        }
    }
}'''

[[reports]]
level = 'Warning'
analyzer = 'UnsafeDestructor'
description = 'unsafe block detected in drop'
location = 'src/channel/spsc.rs:197:1: 236:2'
source = '''
impl<T> Drop for Receiver<T> {
    fn drop(&mut self) {
        loop {
            // This dereferral is safe because we only put nodes allocated from
            // `OwnedAlloc`.
            let next = unsafe {
                // Let's try to mark next's bit so that sender will see we
                // disconnected, if it hasn't disconnected by itself. It is ok
                // to just swap, since we have only two possible
                // values (null and null | 1) and we everyone
                // will be setting to the same value (null | 1).
                self.front.as_ref().next.swap(
                    (null_mut::<Node<T>>() as usize | 1) as *mut _,
                    Acquire,
                )
            };

            // Then we check for null (success of our swap).
            let next_nnptr = match NonNull::new(next) {
                Some(nnptr) => nnptr,
                // If it was null, no other action is required. We should not
                // deallocate it because the sender still sees it through back.
                None => break,
            };

            // It is safe to drop because we are the only ones that
            // have a pointer to the node.
            unsafe { OwnedAlloc::from_raw(self.front) };

            // if next is marked, it is actually null | 1, but we can deallocate
            // it because the sender already disconnected.
            if next as usize & 1 == 1 {
                break;
            }

            // Update the front just like in pop.
            self.front = next_nnptr;
        }
    }
}'''

[[reports]]
level = 'Warning'
analyzer = 'UnsafeDestructor'
description = 'unsafe block detected in drop'
location = 'src/channel/mpsc.rs:282:1: 338:2'
source = '''
impl<T> Drop for Receiver<T> {
    fn drop(&mut self) {
        // This is safe because when senders disconnect, they won't drop the
        // back. The shared back is only deleted when both sides disconnect.
        // And we are the only receiver.
        //
        // Let's check if sender disconnected.
        let mut ptr = unsafe { self.back.as_ref().ptr.load(Relaxed) };
        loop {
            // Bit is marked, sender disconnected.
            if ptr as usize & 1 == 1 {
                // Safe to delete all nodes because sender disconnected and we
                // are the only receiver.
                //
                // Same thing about deleting the shared back (a pointer to a
                // pointer).
                unsafe {
                    self.delete_all();
                    OwnedAlloc::from_raw(self.back);
                }
                break;
            }

            // This is safe because we only store nodes allocated via
            // `OwnedAlloc`. Also, the shared back is only deallocated when both
            // sides have disconnected.
            let res = unsafe {
                // Let's try to mark the back. Needs to be a CAS because the
                // back might change the back to some other pointer it
                // meanwhile.
                self.back.as_ref().ptr.compare_exchange(
                    ptr,
                    (ptr as usize | 1) as *mut _,
                    Relaxed,
                    Relaxed,
                )
            };

            match res {
                // If we succeeded, we need to delete all nodes unreachable by
                // the senders.
                Ok(_) => {
                    // Safe because we pass a pointer to the loaded back as
                    // "last". We cannot even dereference
                    // it. We are also the only ones with
                    // reference to nodes from the front until before last.
                    unsafe {
                        delete_before_last(self.front, Some(bypass_null(ptr)))
                    }
                    break;
                },

                Err(new) => ptr = new,
            }
        }
    }
}'''

[[reports]]
level = 'Warning'
analyzer = 'UnsafeDestructor'
description = 'unsafe block detected in drop'
location = 'src/channel/mpsc.rs:353:1: 396:2'
source = '''
impl<T> Drop for SenderInner<T> {
    fn drop(&mut self) {
        // This is safe because we only store nodes allocated via
        // `OwnedAlloc`. Also, the shared back is only deallocated when both
        // sides disconnected.
        let ptr = unsafe { self.back.as_ref().ptr.load(Relaxed) };

        // Let's check for bit marking. If 1 the receiver is already
        // disconnected. If 0, nobody disconnected yet.
        if ptr as usize & 1 == 0 {
            // This is safe because we only store nodes allocated via
            // `OwnedAlloc`. Also, the shared back is only deallocated when both
            // sides disconnected.
            let res = unsafe {
                // Let's try to bit mark it so receiver will know we
                // disconnected.
                //
                // Safe to be a swap since we are the only ones which store
                // something different from ptr and ptr | 1 and we are not doing
                // so.
                self.back
                    .as_ref()
                    .ptr
                    .swap((ptr as usize | 1) as *mut _, Relaxed)
            };

            if res == ptr {
                // If we succeeded, we will left everything to be deallocated by
                // the receiver.
                return;
            }
        }

        // Falling here means sender disconnected.
        let ptr = (ptr as usize & !1) as *mut Node<T>;
        // This is safe because the pointer stored in the back will
        // never be null. Also, the sender disconnected and we are the
        // only sender left.
        unsafe {
            OwnedAlloc::from_raw(bypass_null(ptr));
            OwnedAlloc::from_raw(self.back);
        };
    }
}'''

[[reports]]
level = 'Warning'
analyzer = 'UnsafeDestructor'
description = 'unsafe block detected in drop'
location = 'src/channel/spmc.rs:107:1: 131:2'
source = '''
impl<T> Drop for Sender<T> {
    fn drop(&mut self) {
        // This dereferral is safe because the queue always have at least one
        // node. This single node is only dropped when the last side to
        // disconnect drops.
        let res = unsafe {
            // Let's try to mark next's bit so that receiver will see we
            // disconnected, if it hasn't disconnected by itself. It is ok to
            // just swap, since we have only two possible values (null and
            // null | 1) and we everyone will be setting to the same value
            // (null | 1).
            self.back
                .as_ref()
                .next
                .swap((null_mut::<Node<T>>() as usize | 1) as *mut _, Relaxed)
        };

        // If the previously stored value was not null, receiver has already
        // disconnected. It is safe to drop because we are the only ones that
        // have a pointer to the node.
        if !res.is_null() {
            unsafe { OwnedAlloc::from_raw(self.back) };
        }
    }
}'''

[[reports]]
level = 'Warning'
analyzer = 'UnsafeDestructor'
description = 'unsafe block detected in drop'
location = 'src/channel/spmc.rs:274:1: 320:2'
source = '''
impl<T> Drop for ReceiverInner<T> {
    fn drop(&mut self) {
        let front = self.front.get_mut();
        loop {
            // This null-check-by-pass is safe because we never store null in
            // the front.
            let front_nnptr = unsafe { bypass_null(*front) };
            // This is safe because we are the only receiver left and the list
            // will always have at least one node, even in the drop. Of course,
            // unless we are the last side to drop (then we do drop it all).
            let res = unsafe {
                // Let's try to mark the next (which means we disconnected). We
                // might fail because either this is not the last node or the
                // sender already disconnected and marked this pointer.
                front_nnptr.as_ref().next.compare_exchange(
                    null_mut(),
                    (null_mut::<Node<T>>() as usize | 1) as *mut _,
                    AcqRel,
                    Acquire,
                )
            };

            match res {
                // If the succeeded, we are the first side to disconnect and we
                // must keep at least one node in the queue.
                Ok(_) => break,

                Err(next) => {
                    // Ok, safe to deallocate the front now. We already loaded
                    // the next field and it is not null.
                    // Either the queue won't be empty or the
                    // sender disconnected.
                    unsafe { OwnedAlloc::from_raw(front_nnptr) };

                    // This means the sender disconnected we reached the end of
                    // the queue.
                    if next as usize & 1 == 1 {
                        break;
                    }

                    // Now let's keep going until the list is empty.
                    *front = next;
                },
            }
        }
    }
}'''

[[reports]]
level = 'Warning'
analyzer = 'UnsafeDestructor'
description = 'unsafe block detected in drop'
location = 'src/channel/mpmc.rs:306:1: 348:2'
source = '''
impl<T> Drop for SenderInner<T> {
    fn drop(&mut self) {
        // This is safe because we only store nodes allocated via
        // `OwnedAlloc`. Also, the shared back is only deallocated when both
        // sides disconnected.
        let ptr = unsafe { self.back.as_ref().ptr.load(Relaxed) };

        // Let's check for bit marking. If 1 the receiver is already
        // disconnected. If 0, nobody disconnected yet.
        if ptr as usize & 1 == 0 {
            // This is safe because we only store nodes allocated via
            // `OwnedAlloc`. Also, the shared back is only deallocated when both
            // sides disconnected.
            let res = unsafe {
                // Let's try to bit mark it so receiver will know we
                // disconnected.
                //
                // Safe to be a swap since we are the only ones which store
                // something different from ptr and ptr | 1 and we are not doing
                // so.
                self.back
                    .as_ref()
                    .ptr
                    .swap((ptr as usize | 1) as *mut _, Release)
            };

            if res == ptr {
                // If we succeeded, we will left everything to be deallocated by
                // the receiver.
                return;
            }
        }

        let ptr = (ptr as usize & !1) as *mut Node<T>;
        // This is safe because the pointer stored in the back will
        // never be null. Also, the sender disconnected and we are the
        // only sender left.
        unsafe {
            OwnedAlloc::from_raw(bypass_null(ptr));
            OwnedAlloc::from_raw(self.back);
        }
    }
}'''

[[reports]]
level = 'Warning'
analyzer = 'UnsafeDestructor'
description = 'unsafe block detected in drop'
location = 'src/channel/mpmc.rs:370:1: 430:2'
source = '''
impl<T> Drop for ReceiverInner<T> {
    fn drop(&mut self) {
        // This is safe because when senders disconnect, they won't drop the
        // back. And we are the only receiver.
        //
        // Let's check if sender disconnected.
        let mut ptr = unsafe { self.back.as_ref().ptr.load(Relaxed) };

        loop {
            // Bit is marked, sender disconnected.
            if ptr as usize & 1 == 1 {
                // Safe to delete all nodes because sender disconnected and we
                // are the only receiver.
                //
                // Same thing about deleting the shared back (a pointer to a
                // pointer).
                unsafe {
                    self.delete_all();
                    OwnedAlloc::from_raw(self.back);
                }
                break;
            }

            // This is safe because we only store nodes allocated via
            // `OwnedAlloc`. Also, the shared back is only deallocated when both
            // sides have disconnected.
            let res = unsafe {
                // Let's try to mark the back. Needs to be a CAS because the
                // back might change the back to some other pointer it
                // meanwhile.
                self.back.as_ref().ptr.compare_exchange(
                    ptr,
                    (ptr as usize | 1) as *mut _,
                    Relaxed,
                    Relaxed,
                )
            };

            match res {
                // If we succeeded, we need to delete all nodes unreachable by
                // the senders.
                Ok(_) => {
                    // Safe because we pass a pointer to the loaded back as
                    // "last". We cannot even dereference
                    // it. We are also the only ones with
                    // reference to nodes from the front until before last.
                    debug_assert!(!ptr.is_null());
                    unsafe {
                        delete_before_last(
                            NonNull::new_unchecked(self.front.load(Relaxed)),
                            NonNull::new(ptr),
                        )
                    }
                    break;
                },

                Err(new) => ptr = new,
            }
        }
    }
}'''

[[reports]]
level = 'Warning'
analyzer = 'UnsafeDestructor'
description = 'unsafe block detected in drop'
location = 'src/removable.rs:112:1: 120:2'
source = '''
impl<T> Drop for Removable<T> {
    fn drop(&mut self) {
        if *self.present.get_mut() {
            // Safe because present will only be true when the memory is
            // initialized. And now we are at drop.
            unsafe { ManuallyDrop::drop(&mut self.item) }
        }
    }
}'''
